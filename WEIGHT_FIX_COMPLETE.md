# ⚠️ 类别权重修正完成（Pre-flight Fix）

## ✅ 修正状态：已完成

修正时间：2026-02-07  
修正文件：`main.py` (第 250-256 行)

---

## 🐛 问题：权重配置过时

### 危险的旧配置
```python
# 旧配置（针对 3% 反讽设计）
class_weights = torch.tensor([1.0, 1.0, 15.0]).to(device)
```

### 为什么危险？
| 配置 | 数据分布 | 权重 | 有效权重 | 结果 |
|------|---------|------|---------|------|
| **旧版本** | Label 2: 3% | 15.0 | 3% × 15 = 45% | ✅ 合理 |
| **新版本** | Label 2: 17% | 15.0 | 17% × 15 = **255%** | ❌ 过度！|

**后果**：
- 模型会疯狂预测反讽
- Recall 极高（> 90%），但 Precision 极低（< 30%）
- 大量正常话被误判为反讽
- 模型过度敏感，不可用

---

## ✅ 修正方案

### 数学计算
```
当前数据分布:
- Label 0 (正面): 42%
- Label 1 (负面): 41%
- Label 2 (反讽): 17%

不平衡比例: 42% / 17% ≈ 2.4

合理权重: 2.5 (略高于 2.4，给予适度补偿)
```

### 新配置
```python
# 新配置（针对 17% 反讽设计）
class_weights = torch.tensor([1.0, 1.0, 2.5]).to(device)
```

### 有效权重验证
```
Label 0: 42% × 1.0 = 42%
Label 1: 41% × 1.0 = 41%
Label 2: 17% × 2.5 = 42.5%

结果: 三个类别基本平衡 ✅
```

---

## 📊 预期效果对比

### 使用 15 倍权重（危险）
```
反讽 Recall:    > 90%  (过高)
反讽 Precision: < 30%  (过低)
反讽 F1:        ~45%   (不平衡)

问题: 模型把所有稍微不对劲的话都猜成反讽
```

### 使用 2.5 倍权重（合理）
```
反讽 Recall:    60-80% (合理)
反讽 Precision: 60-80% (合理)
反讽 F1:        60-80% (平衡)

结果: 模型判断准确，不会过度预测
```

---

## 🔧 代码修改详情

### main.py (第 250-256 行)

**修改前**:
```python
# 三分类加权损失：处理反讽数据不平衡（反讽只占3.56%）
# Label 0 (正面): 权重 1.0
# Label 1 (负面): 权重 1.0
# Label 2 (反讽): 权重 15.0 (算错一个反讽，惩罚力度是正常的15倍)
class_weights = torch.tensor([1.0, 1.0, 15.0]).to(device)
```

**修改后**:
```python
# 三分类加权损失：处理反讽数据不平衡（修复后反讽占17.4%）
# Label 0 (正面): 权重 1.0 (42%)
# Label 1 (负面): 权重 1.0 (41%)
# Label 2 (反讽): 权重 2.5 (17% - 约为正常类别的1/2.4，给予适度补偿)
# 注：修复数据泄露后，反讽比例从3%提升到17%，权重从15降至2.5避免过度预测
class_weights = torch.tensor([1.0, 1.0, 2.5]).to(device)
```

### check_3class_ready.py

**修改前**:
```python
("使用加权损失函数", r"class_weights.*=.*torch\.tensor.*15", "torch.tensor([1.0, 1.0, 15.0])"),
```

**修改后**:
```python
("使用加权损失函数", r"class_weights.*=.*torch\.tensor.*2\.5", "torch.tensor([1.0, 1.0, 2.5])"),
```

---

## 💡 权重选择指南

### 一般原则
| 不平衡程度 | 少数类占比 | 推荐权重 | 说明 |
|-----------|-----------|---------|------|
| 极端不平衡 | < 5% | 10-20 | 旧版本在这里 |
| 严重不平衡 | 5-10% | 5-10 | |
| **中等不平衡** | **10-20%** | **2-5** | **我们在这里** |
| 轻度不平衡 | 20-30% | 1.5-2 | |
| 基本平衡 | > 30% | 1 或不使用 | |

### 计算公式
```python
# 方法 1: 反比例
weight = (majority_ratio / minority_ratio)

# 方法 2: 平方根反比例（更温和）
weight = sqrt(majority_ratio / minority_ratio)

# 我们的情况:
# 方法 1: 42% / 17% = 2.47 → 取 2.5
# 方法 2: sqrt(2.47) = 1.57 → 取 1.5-2.0
```

### 替代方案

如果训练后发现效果不理想，可以尝试：

```python
# 方案 A: 完全移除权重（让数据说话）
criterion = nn.CrossEntropyLoss()

# 方案 B: 更温和的权重（如果反讽被过度预测）
class_weights = torch.tensor([1.0, 1.0, 2.0]).to(device)

# 方案 C: 更激进的权重（如果反讽 Recall 太低）
class_weights = torch.tensor([1.0, 1.0, 3.0]).to(device)
```

---

## ✅ 验证结果

### 检查脚本输出
```bash
$ python check_3class_ready.py

============================================================
📄 检查: main.py
============================================================
✅ num_classes 默认值为 3
✅ 使用加权损失函数
✅ CrossEntropyLoss 使用权重
✅ 添加三分类标签名称

============================================================
✅ 所有检查通过！
============================================================
```

---

## 🎯 修正总结

### 关键改进
- ✅ 权重从 **15.0** 降至 **2.5**（降低 6 倍）
- ✅ 符合当前数据分布（17.4% 反讽）
- ✅ 避免模型过度预测反讽
- ✅ 保持三个类别的平衡

### 修正清单
- [x] 修改 main.py 权重配置
- [x] 更新注释说明
- [x] 修改 check_3class_ready.py
- [x] 验证所有检查通过
- [x] 更新 process.txt 日志

### 文件位置
- 主文件: `main.py` (第 250-256 行)
- 检查脚本: `check_3class_ready.py`
- 开发日志: `process.txt`

---

## 🚀 现在可以安全训练了！

```bash
python main.py --dataset_dir dataset/processed --num_classes 3
```

**重点观察指标**:
- **F1 Macro**: 平等对待每个类别
- **反讽_f1**: Label 2 的 F1 分数
- **反讽_precision**: 避免误报
- **反讽_recall**: 找到真正的反讽

**预期表现**:
- Precision 和 Recall 都在 60-80% 范围
- F1 分数平衡，不会一高一低
- 模型不会疯狂预测反讽

---

## 📝 技术笔记

### 为什么不能用旧权重？

**类比**：
- 旧版本：反讽是"濒危物种"（3%），需要 15 倍保护
- 新版本：反讽是"常见物种"（17%），15 倍保护会导致"泛滥"

**数学证明**：
```
旧版本有效权重: 3% × 15 = 45% ✅
新版本有效权重: 17% × 15 = 255% ❌ (超过 100%！)
```

### 为什么选择 2.5？

1. **数学合理**: 42% / 17% ≈ 2.4
2. **适度补偿**: 2.5 略高于 2.4
3. **经验范围**: 2-3 倍是中等不平衡的标准做法
4. **可调节**: 如果效果不好，可以微调到 2.0 或 3.0

---

**修正完成时间**: 2026-02-07  
**状态**: ✅ 已验证，可以训练  
**下一步**: 开始训练并观察指标
