"""
inference.py
ä¸‰åˆ†ç±»æœ€ç»ˆæ¼”ç¤ºç‰ˆï¼šæ­£é¢ vs è´Ÿé¢ vs é˜´é˜³æ€ªæ°”
"""
import torch
from data_preprocess import DataPreprocessor
from model import BertHGNNModel
import os

# ================= é…ç½®åŒº =================
# å¿…é¡»æŒ‡å‘ä½ åˆšè®­ç»ƒå¥½çš„é‚£ä¸ªæ–‡ä»¶å¤¹
MODEL_DIR = "checkpoints/3class_final" 
MODEL_PATH = os.path.join(MODEL_DIR, "best_model.pth")
BERT_MODEL = "bert-base-chinese"
MAX_LEN = 256
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ========================================

def load_trained_model():
    print("â³ æ­£åœ¨åŠ è½½é¢„å¤„ç†å·¥å…·...")
    preprocessor = DataPreprocessor(bert_model_name=BERT_MODEL)
    
    print(f"â³ æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_PATH} ...")
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}")

    # æ³¨æ„ï¼šè¿™é‡Œçš„å‚æ•°å¿…é¡»å’Œä½  main.py é‡Œçš„å®Œå…¨ä¸€è‡´
    model = BertHGNNModel(
        bert_model_name=BERT_MODEL,
        hgnn_hidden_dims=[256, 128], 
        num_attention_heads=4,
        num_classes=3,  # <--- å…³é”®ï¼šç°åœ¨æ˜¯ 3 åˆ†ç±»
        dropout=0
    )
    
    # åŠ è½½æƒé‡
    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
        
    model.to(DEVICE)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼å‡†å¤‡èµ·é£ï¼")
    return model, preprocessor

def predict(model, preprocessor, text, topic=""):
    # 1. é¢„å¤„ç†
    # å¦‚æœç”¨æˆ·æ²¡è¾“ Topicï¼Œæˆ‘ä»¬ç»™ä¸€ä¸ªä¸­æ€§çš„ Topicï¼Œé˜²æ­¢æ¨¡å‹å› ä¸ºç©º Topic ä¹±çŒœ
    if not topic: 
        topic = "ç½‘å‹è¯„è®º" 
        
    bert_tokens = preprocessor.process_text_pair(text, topic, MAX_LEN)
    hanlp_result = preprocessor.process_text_with_hanlp(text, topic)
    
    # 2. æ„å»ºè¶…å›¾
    max_edges = 50 
    hypergraph_matrix = preprocessor._create_single_hypergraph_matrix(
        hanlp_result, MAX_LEN, max_edges
    )
    
    # 3. è½¬ Tensor
    input_ids = bert_tokens['input_ids'].unsqueeze(0).to(DEVICE)
    attention_mask = bert_tokens['attention_mask'].unsqueeze(0).to(DEVICE)
    token_type_ids = bert_tokens['token_type_ids'].unsqueeze(0).to(DEVICE)
    hg_mat_tensor = torch.tensor(hypergraph_matrix, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    
    # 4. é¢„æµ‹
    with torch.no_grad():
        logits = model(input_ids, attention_mask, hg_mat_tensor, token_type_ids)
        probs = torch.softmax(logits, dim=1)
        pred_label = torch.argmax(probs, dim=1).item()
        
        # è·å–æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡
        prob_0 = probs[0][0].item() # æ­£é¢
        prob_1 = probs[0][1].item() # è´Ÿé¢
        prob_2 = probs[0][2].item() # åè®½
        
    return pred_label, (prob_0, prob_1, prob_2)

if __name__ == "__main__":
    try:
        model, preprocessor = load_trained_model()
        
        print("\n" + "="*40)
        print("ğŸ¤– AI æƒ…æ„Ÿä¸åè®½åˆ†æç»ˆç«¯ (H100é©±åŠ¨ç‰ˆ)")
        print("æ ‡ç­¾å®šä¹‰: [0]æ­£é¢å¤¸å¥–  [1]æ­£å¸¸å·®è¯„  [2]é˜´é˜³æ€ªæ°”")
        print("è¾“å…¥ 'q' é€€å‡º")
        print("="*40 + "\n")
        
        while True:
            print("-" * 30)
            topic = input("åœºæ™¯/æ ‡é¢˜ ã€å¯å›è½¦è·³è¿‡ã€‘: ").strip()
            if topic == 'q': break
            
            text = input("æ–‡æœ¬å†…å®¹: ").strip()
            if text == 'q': break
            if not text: continue
            
            try:
                label, probs = predict(model, preprocessor, text, topic)
                
                # ç»“æœç¾åŒ–
                if label == 0:
                    result = "â¤ï¸  å¿ƒæƒ…ä¸é”™ ã€æ­£å¸¸è¯­æ°”-æ­£é¢ã€‘"
                elif label == 1:
                    result = "ğŸ’”  ä½ å·²æ€¥å“­ ã€æ­£å¸¸è¯­æ°”-è´Ÿé¢ã€‘"
                else:
                    result = "ğŸ˜  é˜´é˜³æ€ªæ°” ã€åè®½è­¦å‘Š!ã€‘"
                
                print(f"\nåˆ†æç»“è®º: {result}")
                print(f"è¯¦ç»†æ¦‚ç‡: æ­£é¢[{probs[0]:.2%}]  è´Ÿé¢[{probs[1]:.2%}]  åè®½[{probs[2]:.2%}]")
                
                # å¼ºæ’‘æ£€æµ‹é€»è¾‘ï¼ˆå½©è›‹ï¼‰
                if label == 0 and probs[2] > 0.3:
                    print("ğŸ’¡ æ´å¯Ÿ: å¬èµ·æ¥å¿ƒæƒ…ä¸é”™ï¼Œä½†æœ‰ä¸€ä¸å¼ºæ’‘çš„å‘³é“...")
                    
            except Exception as e:
                print(f"æ¨ç†å‡ºé”™: {e}")
    except Exception as e:
        print(f"å¯åŠ¨å¤±è´¥: {e}")