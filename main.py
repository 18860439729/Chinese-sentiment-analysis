"""
ä¸»ç¨‹åºå…¥å£
å®éªŒçš„å…¥å£æ–‡ä»¶
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import argparse
import os
import time
from typing import Dict, Any, List, Tuple

from data_preprocess import (
    DataPreprocessor, 
    load_all_datasets, 
    create_data_loaders, 
    SarcasmDataset,
    create_hypergraph_collate_fn  # æ–°å¢ï¼šç”¨äºæµ‹è¯•é›†
)
from model import BertHGNNModel
from utils import (
    set_seed, setup_logging, save_config, load_config, EarlyStopping,
    MetricsCalculator, Visualizer, count_parameters, save_model, load_model,
    get_device, AverageMeter, format_time
)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='BERT + HGNN + Attention æ–‡æœ¬åˆ†ç±»')
    
    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--dataset_dir', type=str, default='dataset', help='æ•°æ®é›†ç›®å½•è·¯å¾„')
    parser.add_argument('--cache_dir', type=str, default='cache', help='ç¼“å­˜ç›®å½•è·¯å¾„')
    parser.add_argument('--train_data', type=str, help='è®­ç»ƒæ•°æ®è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨dataset/train.jsonï¼‰')
    parser.add_argument('--val_data', type=str, help='éªŒè¯æ•°æ®è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨dataset/dev.jsonï¼‰')
    parser.add_argument('--test_data', type=str, help='æµ‹è¯•æ•°æ®è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨dataset/test.jsonï¼‰')
    
    # æ¨¡å‹ç›¸å…³å‚æ•°
    parser.add_argument('--bert_model', type=str, default='bert-base-chinese', 
                       help='BERTæ¨¡å‹åç§°')
    parser.add_argument('--hgnn_hidden_dims', type=int, nargs='+', default=[512, 256],
                       help='HGNNéšè—å±‚ç»´åº¦')
    parser.add_argument('--num_attention_heads', type=int, default=8, 
                       help='æ³¨æ„åŠ›å¤´æ•°')
    parser.add_argument('--num_classes', type=int, default=2, help='åˆ†ç±»ç±»åˆ«æ•°')
    parser.add_argument('--dropout', type=float, default=0.1, help='Dropoutç‡')
    parser.add_argument('--freeze_bert', action='store_true', help='æ˜¯å¦å†»ç»“BERTå‚æ•°')
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--batch_size', type=int, default=16, help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--learning_rate', type=float, default=2e-5, help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=0.01, help='æƒé‡è¡°å‡')
    parser.add_argument('--warmup_steps', type=int, default=500, help='é¢„çƒ­æ­¥æ•°')
    
    # æ—©åœç›¸å…³å‚æ•°
    parser.add_argument('--patience', type=int, default=7, help='æ—©åœå®¹å¿è½®æ•°')
    parser.add_argument('--min_delta', type=float, default=0.001, help='æ—©åœæœ€å°æ”¹å–„å¹…åº¦')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--save_dir', type=str, default='./checkpoints', help='æ¨¡å‹ä¿å­˜ç›®å½•')
    parser.add_argument('--log_dir', type=str, default='./logs', help='æ—¥å¿—ä¿å­˜ç›®å½•')
    parser.add_argument('--config_file', type=str, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', type=str, help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--evaluate_only', action='store_true', help='ä»…è¿›è¡Œè¯„ä¼°')
    
    return parser.parse_args()


def train_epoch(model: nn.Module, 
                train_loader: DataLoader, 
                criterion: nn.Module, 
                optimizer: optim.Optimizer,
                device: torch.device,
                epoch: int,
                logger) -> Tuple[float, float]:
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    
    losses = AverageMeter()
    accuracies = AverageMeter()
    
    start_time = time.time()
    
    for batch_idx, batch in enumerate(train_loader):
        # ç¡¬ä»¶æ— å…³æ€§ï¼šæ•°æ®å·²ç»åœ¨collate_fnä¸­ç§»åˆ°è®¾å¤‡ä¸Š
        input_ids = batch['input_ids']
        attention_mask = batch['attention_mask'] 
        token_type_ids = batch['token_type_ids']
        hypergraph_matrix = batch['hypergraph_matrix']
        labels = batch['labels']
        
        # æ¸…é›¶æ¢¯åº¦
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = model(input_ids, attention_mask, hypergraph_matrix, token_type_ids)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, labels)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
        
        # è®¡ç®—å‡†ç¡®ç‡
        _, predicted = torch.max(outputs.data, 1)
        accuracy = (predicted == labels).float().mean()
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        losses.update(loss.item(), labels.size(0))
        accuracies.update(accuracy.item(), labels.size(0))
        
        # æ‰“å°è¿›åº¦
        if batch_idx % 100 == 0:
            elapsed_time = time.time() - start_time
            logger.info(f'Epoch: {epoch}, Batch: {batch_idx}/{len(train_loader)}, '
                       f'Loss: {losses.avg:.4f}, Acc: {accuracies.avg:.4f}, '
                       f'Time: {format_time(elapsed_time)}')
    
    return losses.avg, accuracies.avg


def validate_epoch(model: nn.Module, 
                  val_loader: DataLoader, 
                  criterion: nn.Module,
                  device: torch.device) -> Tuple[float, float, List[int], List[int]]:
    """éªŒè¯ä¸€ä¸ªepoch"""
    model.eval()
    
    losses = AverageMeter()
    accuracies = AverageMeter()
    
    all_predictions = []
    all_labels = []
    
    with torch.no_grad():
        for batch in val_loader:
            # ç¡¬ä»¶æ— å…³æ€§ï¼šæ•°æ®å·²ç»åœ¨collate_fnä¸­ç§»åˆ°è®¾å¤‡ä¸Š
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            token_type_ids = batch['token_type_ids'] 
            hypergraph_matrix = batch['hypergraph_matrix']
            labels = batch['labels']
            
            # å‰å‘ä¼ æ’­
            outputs = model(input_ids, attention_mask, hypergraph_matrix, token_type_ids)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(outputs, labels)
            
            # è®¡ç®—å‡†ç¡®ç‡
            _, predicted = torch.max(outputs.data, 1)
            accuracy = (predicted == labels).float().mean()
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            losses.update(loss.item(), labels.size(0))
            accuracies.update(accuracy.item(), labels.size(0))
            
            # æ”¶é›†é¢„æµ‹ç»“æœ
            all_predictions.extend(predicted.cpu().numpy().tolist())
            all_labels.extend(labels.cpu().numpy().tolist())
    
    return losses.avg, accuracies.avg, all_predictions, all_labels


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_dir)
    logger.info("å¼€å§‹è®­ç»ƒ...")
    
    # è·å–è®¾å¤‡ - ç¡¬ä»¶æ— å…³æ€§æ ‡å‡†å†™æ³•
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœæä¾›ï¼‰
    if args.config_file and os.path.exists(args.config_file):
        config = load_config(args.config_file)
        logger.info(f"ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°: {args.config_file}")
        # æ›´æ–°argsä¸­çš„å‚æ•°
        for key, value in config.items():
            if hasattr(args, key):
                setattr(args, key, value)
    
    # ä¿å­˜å½“å‰é…ç½®
    config_save_path = os.path.join(args.save_dir, 'config.json')
    save_config(vars(args), config_save_path)
    
    # åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨ - ä¼ å…¥BERTæ¨¡å‹åç§°
    logger.info("åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨...")
    preprocessor = DataPreprocessor(bert_model_name=args.bert_model)
    
    # åŠ è½½æ•°æ® - ä½¿ç”¨å†…ç½®ç¼“å­˜æœºåˆ¶
    logger.info("ğŸ“¥ åŠ è½½æ•°æ®é›†...")
    
    if args.train_data and args.val_data:
        # ä½¿ç”¨æŒ‡å®šçš„æ•°æ®æ–‡ä»¶è·¯å¾„
        from data_preprocess import load_dataset
        train_data = load_dataset(args.train_data)
        val_data = load_dataset(args.val_data)
        test_data = load_dataset(args.test_data) if args.test_data else []
    else:
        # ä½¿ç”¨é»˜è®¤çš„æ•°æ®é›†ç›®å½•
        train_data, val_data, test_data = load_all_datasets(args.dataset_dir)
    
    logger.info(f"è®­ç»ƒæ•°æ®: {len(train_data)} æ ·æœ¬")
    logger.info(f"éªŒè¯æ•°æ®: {len(val_data)} æ ·æœ¬")
    if test_data:
        logger.info(f"æµ‹è¯•æ•°æ®: {len(test_data)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå†…ç½®ç¼“å­˜æœºåˆ¶ï¼Œç¬¬ä¸€æ¬¡è¿è¡Œä¼šæ…¢ï¼Œä¹‹åä¼šå¾ˆå¿«ï¼‰
    logger.info("ğŸ”§ åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå†…ç½®ç¼“å­˜æœºåˆ¶ï¼‰...")
    logger.info("ğŸ’¡ ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè¿›è¡ŒHanLPé¢„å¤„ç†å¹¶ç¼“å­˜ï¼Œä¹‹åå¯åŠ¨ä¼šå¾ˆå¿«")
    train_loader, val_loader = create_data_loaders(
        train_data, val_data, preprocessor, args.batch_size, max_length=256, cache_dir=args.cache_dir
    )
    
    # åˆå§‹åŒ–æ¨¡å‹ - ç¡¬ä»¶æ— å…³æ€§æ ‡å‡†å†™æ³•
    logger.info("åˆå§‹åŒ–æ¨¡å‹...")
    model = BertHGNNModel(
        bert_model_name=args.bert_model,
        hgnn_hidden_dims=args.hgnn_hidden_dims,
        num_attention_heads=args.num_attention_heads,
        num_classes=args.num_classes,
        dropout=args.dropout,
        freeze_bert=args.freeze_bert
    ).to(device)  # åŠ¡å¿…åŠ ä¸Š .to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    num_params = count_parameters(model)
    logger.info(f"æ¨¡å‹å‚æ•°æ•°é‡: {num_params:,}")
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ - åˆ†å±‚å­¦ä¹ ç‡ç­–ç•¥
    criterion = nn.CrossEntropyLoss()
    
    # åˆ†å±‚å­¦ä¹ ç‡ï¼šBERTç”¨å°å­¦ä¹ ç‡å¾®è°ƒï¼ŒHGNN+Attentionç”¨å¤§å­¦ä¹ ç‡è®­ç»ƒ
    bert_params = []
    other_params = []
    
    for name, param in model.named_parameters():
        if 'bert' in name:
            bert_params.append(param)
        else:
            other_params.append(param)
    
    # åˆ›å»ºå‚æ•°ç»„
    optimizer = optim.AdamW([
        {'params': bert_params, 'lr': args.learning_rate, 'weight_decay': args.weight_decay},  # BERT: 2e-5
        {'params': other_params, 'lr': args.learning_rate * 50, 'weight_decay': args.weight_decay}  # HGNN+Attention: 1e-3
    ])
    
    logger.info(f"ä¼˜åŒ–å™¨é…ç½®:")
    logger.info(f"  BERTå‚æ•°: {len(bert_params)} ä¸ª, å­¦ä¹ ç‡: {args.learning_rate}")
    logger.info(f"  HGNN+Attentionå‚æ•°: {len(other_params)} ä¸ª, å­¦ä¹ ç‡: {args.learning_rate * 50}")
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
    
    # æ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=args.patience, min_delta=args.min_delta)
    
    # æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæä¾›æ£€æŸ¥ç‚¹ï¼‰
    start_epoch = 0
    if args.resume and os.path.exists(args.resume):
        logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {args.resume}")
        model, optimizer, start_epoch, _ = load_model(model, optimizer, args.resume)
    
    # å¦‚æœåªè¿›è¡Œè¯„ä¼°
    if args.evaluate_only:
        if not args.resume:
            logger.error("è¯„ä¼°æ¨¡å¼éœ€è¦æä¾›æ¨¡å‹æ£€æŸ¥ç‚¹")
            return
        
        logger.info("å¼€å§‹è¯„ä¼°...")
        val_loss, val_acc, predictions, true_labels = validate_epoch(
            model, val_loader, criterion, device
        )
        
        logger.info(f"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")
        
        # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
        metrics = MetricsCalculator.calculate_metrics(true_labels, predictions)
        for metric, value in metrics.items():
            logger.info(f"{metric}: {value:.4f}")
        
        # æ‰“å°åˆ†ç±»æŠ¥å‘Š
        MetricsCalculator.print_classification_report(true_labels, predictions)
        
        # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        Visualizer.plot_confusion_matrix(true_labels, predictions)
        
        return
    
    # è®­ç»ƒå¾ªç¯
    logger.info("å¼€å§‹è®­ç»ƒ...")
    
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    
    best_val_acc = 0.0
    
    for epoch in range(start_epoch, args.epochs):
        epoch_start_time = time.time()
        
        # è®­ç»ƒ
        train_loss, train_acc = train_epoch(
            model, train_loader, criterion, optimizer, device, epoch, logger
        )
        
        # éªŒè¯
        val_loss, val_acc, predictions, true_labels = validate_epoch(
            model, val_loader, criterion, device
        )
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®°å½•æŒ‡æ ‡
        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        
        epoch_time = time.time() - epoch_start_time
        
        logger.info(f'Epoch {epoch+1}/{args.epochs} - '
                   f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '
                   f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, '
                   f'Time: {format_time(epoch_time)}')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            best_model_path = os.path.join(args.save_dir, 'best_model.pth')
            save_model(model, optimizer, epoch, val_loss, best_model_path)
            logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 10 == 0:
            checkpoint_path = os.path.join(args.save_dir, f'checkpoint_epoch_{epoch+1}.pth')
            save_model(model, optimizer, epoch, val_loss, checkpoint_path)
        
        # æ—©åœæ£€æŸ¥
        if early_stopping(val_loss, model):
            logger.info(f"æ—©åœè§¦å‘ï¼Œåœ¨ç¬¬ {epoch+1} è½®åœæ­¢è®­ç»ƒ")
            break
    
    # è®­ç»ƒå®Œæˆ
    logger.info("è®­ç»ƒå®Œæˆ!")
    logger.info(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    history_plot_path = os.path.join(args.save_dir, 'training_history.png')
    Visualizer.plot_training_history(
        train_losses, val_losses, train_accuracies, val_accuracies, history_plot_path
    )
    
    # æœ€ç»ˆè¯„ä¼°
    logger.info("è¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    best_model_path = os.path.join(args.save_dir, 'best_model.pth')
    if os.path.exists(best_model_path):
        model, _, _, _ = load_model(model, optimizer, best_model_path)
    
    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    val_loss, val_acc, predictions, true_labels = validate_epoch(
        model, val_loader, criterion, device
    )
    
    # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    metrics = MetricsCalculator.calculate_metrics(true_labels, predictions)
    logger.info("æœ€ç»ˆéªŒè¯ç»“æœ:")
    for metric, value in metrics.items():
        logger.info(f"{metric}: {value:.4f}")
    
    # æ‰“å°åˆ†ç±»æŠ¥å‘Š
    MetricsCalculator.print_classification_report(true_labels, predictions)
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    confusion_matrix_path = os.path.join(args.save_dir, 'confusion_matrix.png')
    # å‘Šè¯‰ç”»å›¾å·¥å…·ï¼Œ0æ˜¯æ­£å¸¸ï¼Œ1æ˜¯è®½åˆº
    Visualizer.plot_confusion_matrix(true_labels, predictions, labels=['Normal', 'Sarcastic'], save_path=confusion_matrix_path)
    
    # å¦‚æœæœ‰æµ‹è¯•æ•°æ®ï¼Œè¿›è¡Œæµ‹è¯•
    if test_data and len(test_data) > 0:
        logger.info("åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
        
        # ä¿®å¤ï¼šåˆ›å»º collate_fn å’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨
        logger.info("ğŸ”§ åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨...")
        
        # 1. åˆ›å»º collate_fnï¼ˆä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„é…ç½®ï¼‰
        test_collate_fn = create_hypergraph_collate_fn(preprocessor, max_length=256)
        
        # 2. åˆ›å»ºæµ‹è¯•æ•°æ®é›†ï¼ˆå¸¦ç¼“å­˜ï¼‰
        test_cache_file = os.path.join(args.cache_dir, 'test_cache.pkl')
        test_dataset = SarcasmDataset(test_data, preprocessor, 256, cache_file=test_cache_file)
        
        # 3. åˆ›å»º DataLoaderï¼ˆæ³¨æ„ï¼šnum_workers=0 å› ä¸º collate_fn é‡Œç”¨äº† .to(device)ï¼‰
        test_loader = DataLoader(
            test_dataset, 
            batch_size=args.batch_size, 
            shuffle=False, 
            collate_fn=test_collate_fn,
            num_workers=0  # é‡è¦ï¼šé¿å…å¤šè¿›ç¨‹ä¸GPUå†²çª
        )
        
        logger.info(f"âœ… æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: {len(test_dataset)} æ ·æœ¬")
        
        # è¯„ä¼°æµ‹è¯•é›†
        test_loss, test_acc, test_predictions, test_labels = validate_epoch(model, test_loader, criterion, device)
        logger.info(f"æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")
        
        # æµ‹è¯•é›†è¯¦ç»†æŒ‡æ ‡
        test_metrics = MetricsCalculator.calculate_metrics(test_labels, test_predictions)
        logger.info("æµ‹è¯•é›†ç»“æœ:")
        for metric, value in test_metrics.items():
            logger.info(f"{metric}: {value:.4f}")


if __name__ == '__main__':
    main()