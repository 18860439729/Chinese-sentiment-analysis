import streamlit as st
import torch
import os
import time
import pandas as pd
import random
import graphviz # å¼•å…¥ç”»å›¾å·¥å…·
from data_preprocess import DataPreprocessor
from model import BertHGNNModel
import torch.nn.functional as F

# ================= é…ç½®åŒº =================
PAGE_TITLE = "Mochi | ä¸­æ–‡æƒ…æ„Ÿåˆ†æç³»ç»Ÿ"
PAGE_ICON = "ğŸ¡"
MODEL_DIR = "checkpoints/3class_final"
MODEL_PATH = os.path.join(MODEL_DIR, "best_model.pth")
BERT_MODEL = "bert-base-chinese"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ================= æ ·å¼æ³¨å…¥ (CSS) =================
def set_style():
    st.markdown("""
    <style>
        /* å…¨å±€å­—ä½“è®¾ç½® */
        html, body, [class*="css"] {
            font-family: "PingFang SC", "Microsoft YaHei", "Helvetica Neue", sans-serif;
            color: #555555;
        }
        
        /* æ ‡é¢˜æ ·å¼ */
        h1 {
            color: #FFB7B2; /* æŸ”å’Œç²‰ */
            font-weight: 700;
            text-shadow: 1px 1px 2px #eee;
        }
        h2, h3 {
            color: #AEC6CF; /* é›¾éœ¾è“ */
        }
        
        /* æŒ‰é’®æ ·å¼ */
        div.stButton > button {
            background-color: #AEC6CF;
            color: white;
            border-radius: 20px;
            border: none;
            height: 50px;
            font-size: 16px;
            font-weight: bold;
            transition: all 0.3s;
        }
        div.stButton > button:hover {
            background-color: #FFB7B2;
            transform: scale(1.02);
        }
        
        /* ç»“æœå¡ç‰‡ */
        .result-card {
            background-color: #FDFD96;
            padding: 20px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            text-align: center;
            margin-bottom: 20px;
            animation: fadeIn 0.8s;
        }
        
        /* åŠ¨ç”»å®šä¹‰ */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        #MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

# ================= æ ¸å¿ƒé€»è¾‘ =================
@st.cache_resource
def load_model():
    # æ¨¡æ‹ŸåŠ è½½è¿›åº¦
    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()
    steps = ["åˆå§‹åŒ– Mochi å†…æ ¸...", "åŠ è½½ BERT è¯­ä¹‰ç©ºé—´...", "æ„å»ºè¶…å›¾ç¥ç»å›è·¯...", "å”¤é†’ Mochi..."]
    for i, step in enumerate(steps):
        status_text.text(step)
        progress_bar.progress((i + 1) * 25)
        time.sleep(0.1)
        
    try:
        preprocessor = DataPreprocessor(bert_model_name=BERT_MODEL)
        model = BertHGNNModel(
            bert_model_name=BERT_MODEL,
            hgnn_hidden_dims=[256, 128],
            num_attention_heads=4,
            num_classes=3,
            dropout=0
        )
        if os.path.exists(MODEL_PATH):
            try:
                checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)
            except TypeError:
                checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
            
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
        else:
            return None, None
            
        model.to(DEVICE)
        model.eval()
        
        status_text.empty()
        progress_bar.empty()
        return model, preprocessor
    except Exception as e:
        st.error(f"Mochi ç”Ÿç—…äº†: {str(e)}")
        return None, None

def predict(model, preprocessor, text, topic):
    if not topic or not topic.strip():
        topic = "ç½‘å‹è¯„è®º"
    bert_tokens = preprocessor.process_text_pair(text, topic, 256)
    hanlp_result = preprocessor.process_text_with_hanlp(text, topic)
    hypergraph_matrix = preprocessor._create_single_hypergraph_matrix(hanlp_result, 256, 50)
    
    input_ids = bert_tokens['input_ids'].unsqueeze(0).to(DEVICE)
    attention_mask = bert_tokens['attention_mask'].unsqueeze(0).to(DEVICE)
    token_type_ids = bert_tokens['token_type_ids'].unsqueeze(0).to(DEVICE)
    hg_mat_tensor = torch.tensor(hypergraph_matrix, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    
    with torch.no_grad():
        logits = model(input_ids, attention_mask, hg_mat_tensor, token_type_ids)
        probs = F.softmax(logits, dim=1)
        
    return probs.cpu().numpy()[0], hanlp_result

# ================= é¡µé¢ä¸»ç»“æ„ =================
st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON, layout="wide")
set_style()

# ä¾§è¾¹æ 
with st.sidebar:
    st.image("https://api.dicebear.com/7.x/notionists/svg?seed=Mochi&backgroundColor=ffb7b2", width=100)
    st.title("Mochi æ§åˆ¶å°")
    st.caption("Ver 1.0.0 (Thesis Build)")
    menu = st.radio("åŠŸèƒ½å¯¼èˆª", ["ğŸš€ æƒ…æ„Ÿåˆ†æå®éªŒå®¤", "ğŸ“Š æ‰¹é‡æ•°æ®å¤„ç†", "ğŸ”Œ API æ¥å£æ–‡æ¡£", "âš™ï¸ ç³»ç»Ÿè®¾ç½®", "ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ"])
    if menu != "ğŸš€ æƒ…æ„Ÿåˆ†æå®éªŒå®¤":
        st.info("âš ï¸ è¯¥æ¨¡å—ä»…å¯¹ VIP å¼€æ”¾ï¼Œæ¼”ç¤ºç‰ˆè¯·ä½¿ç”¨ã€æƒ…æ„Ÿåˆ†æå®éªŒå®¤ã€‘ã€‚")
    st.markdown("---")
    st.markdown("#### ğŸ› ï¸ æ¨¡å‹å‚æ•°")
    st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.85)
    st.toggle("å¼€å¯å¥æ³•å»å™ª", value=True)

# ä¸»ç•Œé¢
col_main, col_right = st.columns([2, 1])

with col_main:
    st.title(f"{PAGE_ICON} Mochi")
    st.markdown("### ã€ä¸­æ–‡ã€‘çŸ­æ–‡æœ¬æƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    st.caption("åŸºäº **è¶…å›¾ç¥ç»ç½‘ç»œ (HGNN) ä¸æ³¨æ„åŠ›æœºåˆ¶** çš„å¤šæ¨¡æ€æƒ…æ„Ÿè®¡ç®—å¼•æ“")
    
    with st.container():
        st.markdown("#### ğŸ“ æ–‡æœ¬è¾“å…¥")
        col_input1, col_input2 = st.columns([1, 2])
        with col_input1:
            input_topic = st.text_input("è¯­å¢ƒ/è¯é¢˜ (Topic)", placeholder="ä¾‹å¦‚ï¼šå¤–å–")
        with col_input2:
            input_text = st.text_input("è¯„è®ºå†…å®¹ (Text)", placeholder="è¯·è¾“å…¥éœ€è¦åˆ†æçš„ä¸­æ–‡çŸ­æ–‡æœ¬...")
            
        analyze_btn = st.button("å¼€å§‹åˆ†æ / Analyze âœ¨", use_container_width=True)

# é€»è¾‘å¤„ç†
if analyze_btn and input_text:
    model, preprocessor = load_model()
    if model:
        with col_main:
            with st.status("ğŸ§  Mochi æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
                st.write("ğŸ” åˆ†è¯ä¸è¯æ€§æ ‡æ³¨ (HanLP)...")
                time.sleep(0.3)
                st.write("ğŸ•¸ï¸ æ„å»ºä¾å­˜å¥æ³•è¶…å›¾ (Dependency Hypergraph)...")
                time.sleep(0.3)
                probs, hanlp_data = predict(model, preprocessor, input_text, input_topic)
                status.update(label="âœ… åˆ†æå®Œæˆ!", state="complete", expanded=False)
            
            # --- ç»“æœæ–‡æ¡ˆå®šåˆ¶ ---
            pred_label = probs.argmax()
            
            if pred_label == 0:
                main_text = "å¿ƒæƒ…ä¸é”™"
                sub_text = "ã€æ­£å¸¸è¯­æ°”-æ­£é¢ã€‘ (Positive)"
                emoji = "ğŸ’–"
                color = "#ccffcc" 
            elif pred_label == 1:
                main_text = "ä½ å·²æ€¥å“­" 
                sub_text = "ã€æ­£å¸¸è¯­æ°”-è´Ÿé¢ã€‘ (Negative)"
                emoji = "ğŸ’”"
                color = "#f0f2f6" 
            else:
                main_text = "é˜´é˜³æ€ªæ°”"
                sub_text = "ã€åè®½è­¦å‘Šï¼ã€‘ (Sarcasm)"
                emoji = "ğŸ˜"
                color = "#FFB7B2" 
            
            st.markdown(f"""
            <div class="result-card" style="background-color: {color};">
                <h1 style="color: #555; margin:0;">{emoji} {main_text}</h1>
                <h3 style="color: #333; margin:10px;">{sub_text}</h3>
                <p>ç½®ä¿¡åº¦: <strong>{probs[pred_label]:.2%}</strong></p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("#### ğŸ“Š æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ")
            col_p1, col_p2, col_p3 = st.columns(3)
            col_p1.metric("â¤ï¸ æ­£é¢", f"{probs[0]:.1%}")
            col_p1.progress(float(probs[0]))
            col_p2.metric("ğŸ’” è´Ÿé¢", f"{probs[1]:.1%}")
            col_p2.progress(float(probs[1]))
            col_p3.metric("ğŸ˜ åè®½", f"{probs[2]:.1%}")
            col_p3.progress(float(probs[2]))

        # --- Mochi è§†è§’ (Graphviz è¶…å›¾å¯è§†åŒ– - ä¿®å¤ç‰ˆ) ---
        with col_right:
            st.markdown("### ğŸ” Mochi çš„è§†è§’")
            st.info("è¿™æ˜¯ HGNN çœ¼ä¸­çš„å¥å­ç»“æ„ï¼ˆä¾å­˜å¥æ³•è¶…å›¾ï¼‰")
            
            try:
                # 1. ä¸¥æ ¼ä½¿ç”¨ä½ ç¯å¢ƒè¿”å›çš„é”®å
                words = hanlp_data.get('tokens') # ä¹‹å‰æ˜¯ tok
                deps = hanlp_data.get('dependencies') # ä¹‹å‰æ˜¯ dep
                
                # æœ‰äº› HanLP ç‰ˆæœ¬ä¼šåµŒå¥—ä¸€å±‚åˆ—è¡¨ï¼Œåšä¸ªé˜²å¾¡æ€§å¤„ç†
                if words and isinstance(words[0], list):
                    words = words[0]
                if deps and isinstance(deps[0], list) and isinstance(deps[0][0], tuple) == False:
                     # è¿™ç§æƒ…å†µä¸‹ deps å¯èƒ½æ˜¯ [[head, rel], [head, rel]...] æˆ–è€…æ˜¯ [[[head, rel]...]]
                    if isinstance(deps[0][0], list):
                        deps = deps[0]

                if words and deps:
                    # ä½¿ç”¨ Graphviz ç”»å‡ºè¶…å›¾ç»“æ„
                    graph = graphviz.Digraph()
                    graph.attr(rankdir='LR', size='8,5', bgcolor='transparent')
                    graph.attr('node', shape='ellipse', style='filled', fillcolor='#f0f2f6', fontname='Microsoft YaHei')
                    graph.attr('edge', fontname='Microsoft YaHei', fontsize='10', color='#AEC6CF')
                    
                    # å…ˆç”»æ‰€æœ‰èŠ‚ç‚¹
                    for i, w in enumerate(words):
                        graph.node(str(i), w)
                    
                    # å†ç”»è¾¹
                    edge_count = 0
                    for i, item in enumerate(deps):
                        # ä¸åŒçš„ HanLP ç‰ˆæœ¬ï¼Œdeps çš„æ ¼å¼ä¸åŒï¼Œè¿™é‡Œåšå…¼å®¹
                        # æ ¼å¼A: (head_word, relation) -> å­—ç¬¦ä¸²
                        # æ ¼å¼B: (head_index, relation) -> æ•°å­—ç´¢å¼• (æœ€å¸¸è§)
                        head = None
                        rel = None
                        
                        if isinstance(item, (list, tuple)):
                            if len(item) >= 2:
                                head = item[0]
                                rel = item[1]
                        
                        # å¦‚æœ head æ˜¯ç´¢å¼• (æ•°å­—)
                        if isinstance(head, int):
                            head_idx = head - 1 # HanLP ç´¢å¼•é€šå¸¸ä»1å¼€å§‹ï¼ŒGraphvizä»0å¼€å§‹
                            if head_idx >= 0 and head_idx < len(words):
                                # è¿‡æ»¤æ‰ä¸é‡è¦çš„è¾¹ï¼Œåªå±•ç¤ºæ ¸å¿ƒå¥æ³•ï¼Œé¿å…å›¾å¤ªä¹±
                                if rel in ['nsubj', 'obj', 'dobj', 'advmod', 'root', 'att', 'punct']:
                                    graph.edge(str(i), str(head_idx), label=rel)
                                    edge_count += 1
                                    
                        # å¦‚æœ head å·²ç»æ˜¯è¯ (å­—ç¬¦ä¸²)ï¼Œè¯´æ˜ HanLP ç›´æ¥è¿”å›äº†è¯
                        elif isinstance(head, str):
                             # è¿™ç§æ¯”è¾ƒéš¾å¯¹åº”ç´¢å¼•ï¼Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥ç”»è™šèŠ‚ç‚¹ï¼ˆè¾ƒå°‘è§ï¼‰
                             pass

                    if edge_count > 0:
                        st.graphviz_chart(graph)
                        st.caption(f"âœ¨ ä¾å­˜å¥æ³•å¯è§†åŒ–æˆåŠŸï¼å…±æ•è· {edge_count} æ¡æ ¸å¿ƒè¯­ä¹‰è¶…è¾¹ã€‚")
                        st.markdown("""
                        > **å›¾ä¾‹è§£é‡Šï¼š**
                        > * `nsubj`: åè¯æ€§ä¸»è¯­ (è°?)
                        > * `dobj`: ç›´æ¥å®¾è¯­ (ä»€ä¹ˆ?)
                        > * `advmod`: çŠ¶è¯­ä¿®é¥° (æ€ä¹ˆæ ·?)
                        """)
                    else:
                        st.warning("å¥å­ç»“æ„ç®€å•æˆ–è§£ææ ¼å¼ä¸åŒ¹é…ï¼Œæœªç”»å‡ºè¿çº¿ã€‚")
                        st.write(f"Raw Deps: {deps[:2]}") # è°ƒè¯•ç”¨
                else:
                    st.error("æ•°æ®è§£æå¤±è´¥ï¼Œé”®ååŒ¹é…ä½†å†…å®¹ä¸ºç©ºã€‚")
                    st.write(f"Available keys: {list(hanlp_data.keys())}")
                        
            except Exception as e:
                st.error("å¯è§†åŒ–æ¸²æŸ“é­é‡æœªçŸ¥é”™è¯¯")
                st.caption(f"Error Details: {str(e)}")
            
            st.markdown("---")
            st.caption("Generated by Mochi Engine v1.0")

else:
    # æ¬¢è¿é¡µ
    with col_main:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æ¨¡å¼ï¼Œæˆ–ç›´æ¥åœ¨ä¸Šæ–¹è¾“å…¥æ–‡æœ¬å¼€å§‹ä½“éªŒã€‚")
        st.markdown("""
        > **Mochi** æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå¬æ‡‚â€œè¨€å¤–ä¹‹æ„â€çš„æ™ºèƒ½åŠ©æ‰‹ã€‚
        > å®ƒå¯ä»¥åŒºåˆ†ï¼š
        > * ğŸ˜„ **çœŸè¯šçš„èµç¾** (Happy)
        > * ğŸ˜¡ **ç›´ç™½çš„æ‰¹è¯„** (Angry)
        > * ğŸ˜ **é˜´é˜³æ€ªæ°”çš„è®½åˆº** (Sarcasm - æœ€éš¾çš„ï¼)
        """)