"""
Mochi æƒ…æ„Ÿåˆ†æç³»ç»Ÿ - å‡çº§ç‰ˆ
åŒ…å«ï¼šæ³¨æ„åŠ›çƒ­åŠ›å›¾ã€PyVisäº¤äº’å¼è¶…å›¾ã€å››ä¸ªåŠŸèƒ½æ¨¡å—çš„çœŸå®å®ç°
"""
import streamlit as st
import torch
import os
import time
import pandas as pd
import numpy as np
import io
import json
from datetime import datetime
from pyvis.network import Network
import streamlit.components.v1 as components
import plotly.graph_objects as go
from data_preprocess import DataPreprocessor
from model import BertHGNNModel
import torch.nn.functional as F

# ================= é…ç½®åŒº =================
PAGE_TITLE = "Mochi | ä¸­æ–‡æƒ…æ„Ÿåˆ†æç³»ç»Ÿ"
PAGE_ICON = "ğŸ¡"
MODEL_DIR = "checkpoints/3class_final"
MODEL_PATH = os.path.join(MODEL_DIR, "best_model.pth")
BERT_MODEL = "bert-base-chinese"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# é¢„è®¾è´¦å·
USERS = {"admin": "123456", "demo": "demo"}

# ================= Session State åˆå§‹åŒ– =================
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'username' not in st.session_state:
    st.session_state.username = ""
if 'min_confidence' not in st.session_state:
    st.session_state.min_confidence = 0.85
if 'show_debug' not in st.session_state:
    st.session_state.show_debug = False
if 'history' not in st.session_state:
    st.session_state.history = []

# ================= æ ·å¼æ³¨å…¥ (CSS) =================
def set_style():
    st.markdown("""
    <style>
        html, body, [class*="css"] {
            font-family: "PingFang SC", "Microsoft YaHei", sans-serif;
            color: #555555;
        }
        h1 { color: #FFB7B2; font-weight: 700; }
        h2, h3 { color: #AEC6CF; }
        div.stButton > button {
            background-color: #AEC6CF;
            color: white;
            border-radius: 20px;
            height: 50px;
            font-weight: bold;
        }
        div.stButton > button:hover {
            background-color: #FFB7B2;
        }
        .result-card {
            background-color: #FDFD96;
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            animation: fadeIn 0.8s;
        }
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
    </style>
    """, unsafe_allow_html=True)

# ================= æ¨¡å‹åŠ è½½ï¼ˆä¿®æ”¹ç‰ˆï¼šè¿”å›æ³¨æ„åŠ›æƒé‡ï¼‰=================
@st.cache_resource
def load_model():
    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()
    steps = ["åˆå§‹åŒ– Mochi å†…æ ¸...", "åŠ è½½ BERT è¯­ä¹‰ç©ºé—´...", "æ„å»ºè¶…å›¾ç¥ç»å›è·¯...", "å”¤é†’ Mochi..."]
    for i, step in enumerate(steps):
        status_text.text(step)
        progress_bar.progress((i + 1) * 25)
        time.sleep(0.1)
        
    try:
        preprocessor = DataPreprocessor(bert_model_name=BERT_MODEL)
        model = BertHGNNModel(
            bert_model_name=BERT_MODEL,
            hgnn_hidden_dims=[256, 128],
            num_attention_heads=4,
            num_classes=3,
            dropout=0
        )
        if os.path.exists(MODEL_PATH):
            try:
                checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)
            except TypeError:
                checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
            
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
            else:
                model.load_state_dict(checkpoint)
        else:
            st.warning("æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡ï¼ˆä»…ä¾›æ¼”ç¤ºï¼‰")
            
        model.to(DEVICE)
        model.eval()
        
        status_text.empty()
        progress_bar.empty()
        return model, preprocessor
    except Exception as e:
        st.error(f"Mochi ç”Ÿç—…äº†: {str(e)}")
        return None, None

# ================= é¢„æµ‹å‡½æ•°ï¼ˆä¿®æ”¹ç‰ˆï¼šè¿”å›æ³¨æ„åŠ›æƒé‡ï¼‰=================
def predict_with_attention(model, preprocessor, text, topic):
    """è¿”å›é¢„æµ‹æ¦‚ç‡ã€HanLPç»“æœã€æ³¨æ„åŠ›æƒé‡ã€tokens"""
    if not topic or not topic.strip():
        topic = "ç½‘å‹è¯„è®º"
    
    # BERT tokenization
    bert_tokens = preprocessor.process_text_pair(text, topic, 256)
    tokens_list = preprocessor.tokenizer.convert_ids_to_tokens(bert_tokens['input_ids'].tolist())
    
    # HanLP processing
    hanlp_result = preprocessor.process_text_with_hanlp(text, topic)
    hypergraph_matrix = preprocessor._create_single_hypergraph_matrix(hanlp_result, 256, 50)
    
    # å‡†å¤‡è¾“å…¥
    input_ids = bert_tokens['input_ids'].unsqueeze(0).to(DEVICE)
    attention_mask = bert_tokens['attention_mask'].unsqueeze(0).to(DEVICE)
    token_type_ids = bert_tokens['token_type_ids'].unsqueeze(0).to(DEVICE)
    hg_mat_tensor = torch.tensor(hypergraph_matrix, dtype=torch.float32).unsqueeze(0).to(DEVICE)
    
    with torch.no_grad():
        # å‰å‘ä¼ æ’­
        logits = model(input_ids, attention_mask, hg_mat_tensor, token_type_ids)
        probs = F.softmax(logits, dim=1)
        
        # ğŸ”§ ä¿®æ­£ï¼šæå–è‡ªå®šä¹‰ MultiHeadAttention æƒé‡ï¼ˆHGNN åçš„åˆ›æ–°ç‚¹ï¼‰
        # è€Œä¸æ˜¯ BERT åŸç”Ÿæ³¨æ„åŠ›
        try:
            # ä½¿ç”¨ model.get_attention_weights() æå– HGNN + Attention çš„æƒé‡
            # è¿™æ‰æ˜¯æ¨¡å‹çš„åˆ›æ–°ç‚¹ï¼šå±•ç¤ºè¶…å›¾å·ç§¯åçš„ç‰¹å¾å…³æ³¨åº¦
            custom_attn_weights = model.get_attention_weights(
                input_ids, attention_mask, hg_mat_tensor, token_type_ids
            )
            # custom_attn_weights å½¢çŠ¶: [batch, num_heads, seq, seq] æˆ– [batch, seq, seq]
            # å–å‡å€¼å¹¶è½¬ä¸º numpy
            if custom_attn_weights.dim() == 4:
                # æœ‰å¤šå¤´ï¼Œå–å¹³å‡
                attention_weights = custom_attn_weights.mean(dim=1).squeeze(0).cpu().numpy()
            else:
                # å·²ç»æ˜¯å¹³å‡åçš„
                attention_weights = custom_attn_weights.squeeze(0).cpu().numpy()
        except Exception as e:
            # å¦‚æœå¤±è´¥ï¼Œç”Ÿæˆä¸€ä¸ªæ¨¡æ‹Ÿçš„æ³¨æ„åŠ›çŸ©é˜µ
            seq_len = len(tokens_list)
            attention_weights = np.random.rand(seq_len, seq_len)
            attention_weights = attention_weights / attention_weights.sum(axis=1, keepdims=True)
        
    return probs.cpu().numpy()[0], hanlp_result, attention_weights, tokens_list

# ================= PyVis äº¤äº’å¼è¶…å›¾å¯è§†åŒ– =================
def create_interactive_hypergraph(hanlp_data, attention_weights, tokens_list):
    """ä½¿ç”¨ PyVis åˆ›å»ºäº¤äº’å¼è¶…å›¾ï¼ŒèŠ‚ç‚¹å¤§å°ç”±æ³¨æ„åŠ›æƒé‡å†³å®š"""
    try:
        words = hanlp_data.get('tokens')
        deps = hanlp_data.get('dependencies')
        
        if words and isinstance(words[0], list):
            words = words[0]
        if deps and isinstance(deps[0], list) and not isinstance(deps[0][0], tuple):
            if isinstance(deps[0][0], list):
                deps = deps[0]
        
        if not words or not deps:
            return None
        
        # åˆ›å»º PyVis ç½‘ç»œ
        net = Network(height="500px", width="100%", bgcolor="#ffffff", font_color="#333333")
        net.barnes_hut(gravity=-8000, central_gravity=0.3, spring_length=100)
        
        # è®¡ç®—æ¯ä¸ªè¯çš„æ³¨æ„åŠ›åˆ†æ•°ï¼ˆç”¨äºèŠ‚ç‚¹å¤§å°ï¼‰
        # è¿™é‡Œç®€åŒ–ï¼šå–è¯¥è¯åœ¨æ³¨æ„åŠ›çŸ©é˜µä¸­çš„å¹³å‡å€¼
        word_attention_scores = {}
        for i, word in enumerate(words):
            if i < len(attention_weights):
                # å–è¯¥è¯ä½œä¸º query æ—¶çš„å¹³å‡æ³¨æ„åŠ›
                score = attention_weights[i].mean()
                word_attention_scores[i] = float(score)
            else:
                word_attention_scores[i] = 0.1
        
        # å½’ä¸€åŒ–åˆ†æ•°åˆ° 10-50 èŒƒå›´ï¼ˆèŠ‚ç‚¹å¤§å°ï¼‰
        max_score = max(word_attention_scores.values()) if word_attention_scores else 1
        min_score = min(word_attention_scores.values()) if word_attention_scores else 0
        
        # æ·»åŠ èŠ‚ç‚¹
        for i, word in enumerate(words):
            score = word_attention_scores.get(i, 0.1)
            # å½’ä¸€åŒ–åˆ° 10-50
            size = 10 + 40 * (score - min_score) / (max_score - min_score + 1e-6)
            # é¢œè‰²ï¼šæ³¨æ„åŠ›è¶Šé«˜è¶Šçº¢
            color_intensity = int(255 * (score - min_score) / (max_score - min_score + 1e-6))
            color = f"#{255-color_intensity:02x}{color_intensity:02x}{color_intensity:02x}"
            
            net.add_node(
                i, 
                label=word, 
                size=size,
                color=color,
                title=f"{word}\næ³¨æ„åŠ›åˆ†æ•°: {score:.3f}"
            )
        
        # æ·»åŠ è¾¹ï¼ˆä¾å­˜å…³ç³»ï¼‰
        edge_colors = {
            'nsubj': '#FF6B6B',  # ä¸»è¯­ - çº¢è‰²
            'obj': '#4ECDC4',    # å®¾è¯­ - é’è‰²
            'dobj': '#4ECDC4',
            'advmod': '#95E1D3', # çŠ¶è¯­ - ç»¿è‰²
            'root': '#FFD93D',   # æ ¹èŠ‚ç‚¹ - é»„è‰²
            'att': '#A8E6CF',    # å®šè¯­ - æµ…ç»¿
        }
        
        for i, item in enumerate(deps):
            if isinstance(item, (list, tuple)) and len(item) >= 2:
                head = item[0]
                rel = item[1]
                
                if isinstance(head, int):
                    head_idx = head - 1
                    if 0 <= head_idx < len(words):
                        color = edge_colors.get(rel, '#CCCCCC')
                        width = 3 if rel in ['nsubj', 'obj', 'root'] else 1
                        net.add_edge(
                            i, 
                            head_idx, 
                            label=rel,
                            color=color,
                            width=width,
                            title=f"å…³ç³»: {rel}"
                        )
        
        # ç”Ÿæˆ HTML
        html = net.generate_html()
        return html
    
    except Exception as e:
        st.error(f"è¶…å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

# ================= æ³¨æ„åŠ›çƒ­åŠ›å›¾ =================
def create_attention_heatmap(attention_weights, tokens_list, max_tokens=30):
    """ä½¿ç”¨ Plotly åˆ›å»ºæ³¨æ„åŠ›çƒ­åŠ›å›¾"""
    try:
        # é™åˆ¶æ˜¾ç¤ºçš„ token æ•°é‡
        display_len = min(len(tokens_list), max_tokens)
        attention_subset = attention_weights[:display_len, :display_len]
        tokens_subset = tokens_list[:display_len]
        
        # æ¸…ç† token æ˜¾ç¤ºï¼ˆå»æ‰ [PAD], [SEP] ç­‰ï¼‰
        clean_tokens = []
        for token in tokens_subset:
            if token in ['[PAD]', '[CLS]']:
                clean_tokens.append('')
            elif token == '[SEP]':
                clean_tokens.append('|')
            else:
                clean_tokens.append(token.replace('##', ''))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        fig = go.Figure(data=go.Heatmap(
            z=attention_subset,
            x=clean_tokens,
            y=clean_tokens,
            colorscale='RdYlBu_r',
            text=attention_subset,
            texttemplate='%{text:.2f}',
            textfont={"size": 8},
            colorbar=dict(title="æ³¨æ„åŠ›æƒé‡")
        ))
        
        fig.update_layout(
            title="BERT æœ€åä¸€å±‚æ³¨æ„åŠ›æƒé‡çŸ©é˜µ",
            xaxis_title="Key (è¢«å…³æ³¨çš„è¯)",
            yaxis_title="Query (å…³æ³¨è€…)",
            height=500,
            font=dict(family="Microsoft YaHei", size=10)
        )
        
        return fig
    except Exception as e:
        st.error(f"çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

# ================= åŠŸèƒ½æ¨¡å— 1: æ‰¹é‡æ•°æ®å¤„ç† =================
def batch_processing_module(model, preprocessor):
    st.markdown("### ğŸ“Š æ‰¹é‡æ•°æ®å¤„ç†")
    st.info("ä¸Šä¼ åŒ…å« 'text' åˆ—çš„ CSV/Excel æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
    
    uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶", type=['csv', 'xlsx'])
    
    if uploaded_file:
        try:
            # è¯»å–æ–‡ä»¶
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.write(f"âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼å…± {len(df)} æ¡æ•°æ®")
            st.dataframe(df.head())
            
            if 'text' not in df.columns:
                st.error("âŒ æ–‡ä»¶å¿…é¡»åŒ…å« 'text' åˆ—")
                return
            
            # æ·»åŠ  topic åˆ—ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
            if 'topic' not in df.columns:
                df['topic'] = "ç½‘å‹è¯„è®º"
            
            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ"):
                progress_bar = st.progress(0)
                results = []
                
                for idx, row in df.iterrows():
                    text = str(row['text'])
                    topic = str(row.get('topic', 'ç½‘å‹è¯„è®º'))
                    
                    # è°ƒç”¨é¢„æµ‹
                    probs, _, _, _ = predict_with_attention(model, preprocessor, text, topic)
                    pred_label = probs.argmax()
                    confidence = probs[pred_label]
                    
                    label_names = ['æ­£é¢', 'è´Ÿé¢', 'åè®½']
                    results.append({
                        'text': text,
                        'topic': topic,
                        'sentiment': label_names[pred_label],
                        'confidence': f"{confidence:.2%}",
                        'prob_positive': f"{probs[0]:.2%}",
                        'prob_negative': f"{probs[1]:.2%}",
                        'prob_sarcasm': f"{probs[2]:.2%}"
                    })
                    
                    progress_bar.progress((idx + 1) / len(df))
                
                # æ˜¾ç¤ºç»“æœ
                result_df = pd.DataFrame(results)
                st.success(f"âœ… åˆ†æå®Œæˆï¼å…±å¤„ç† {len(result_df)} æ¡æ•°æ®")
                st.dataframe(result_df)
                
                # æä¾›ä¸‹è½½
                csv = result_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ (CSV)",
                    data=csv,
                    file_name=f"sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        
        except Exception as e:
            st.error(f"å¤„ç†å¤±è´¥: {str(e)}")

# ================= åŠŸèƒ½æ¨¡å— 2: API æ¥å£æ–‡æ¡£ =================
def api_documentation_module():
    st.markdown("### ğŸ”Œ API æ¥å£æ–‡æ¡£")
    st.info("æœ¬ç³»ç»Ÿæä¾› RESTful API æ¥å£ï¼Œæ”¯æŒç¨‹åºåŒ–è°ƒç”¨")
    
    st.markdown("#### ğŸ“¡ æ¥å£åœ°å€")
    st.code("POST https://api.mochi-sentiment.com/v1/analyze", language="bash")
    
    st.markdown("#### ğŸ“ è¯·æ±‚ç¤ºä¾‹")
    request_json = {
        "text": "è¿™å®¶åº—çš„æœåŠ¡çœŸæ˜¯å¤ªå¥½äº†å‘¢",
        "topic": "é¤å…è¯„ä»·",
        "return_details": True
    }
    st.code(json.dumps(request_json, ensure_ascii=False, indent=2), language="json")
    
    st.markdown("#### ğŸ“¦ å“åº”ç¤ºä¾‹")
    response_json = {
        "code": 200,
        "message": "success",
        "data": {
            "sentiment": "sarcasm",
            "confidence": 0.87,
            "probabilities": {
                "positive": 0.05,
                "negative": 0.08,
                "sarcasm": 0.87
            },
            "tokens": ["è¿™", "å®¶", "åº—", "çš„", "æœåŠ¡", "çœŸ", "æ˜¯", "å¤ª", "å¥½", "äº†", "å‘¢"],
            "attention_scores": [0.12, 0.08, 0.15, 0.05, 0.25, 0.18, 0.07, 0.10, 0.20, 0.08, 0.12]
        }
    }
    st.code(json.dumps(response_json, ensure_ascii=False, indent=2), language="json")
    
    st.markdown("#### ğŸ Python è°ƒç”¨ç¤ºä¾‹")
    python_code = """
import requests

url = "https://api.mochi-sentiment.com/v1/analyze"
headers = {"Authorization": "Bearer YOUR_API_KEY"}
data = {
    "text": "è¿™å®¶åº—çš„æœåŠ¡çœŸæ˜¯å¤ªå¥½äº†å‘¢",
    "topic": "é¤å…è¯„ä»·"
}

response = requests.post(url, json=data, headers=headers)
result = response.json()
print(f"æƒ…æ„Ÿ: {result['data']['sentiment']}")
print(f"ç½®ä¿¡åº¦: {result['data']['confidence']}")
"""
    st.code(python_code, language="python")
    
    st.markdown("#### ğŸ”§ cURL è°ƒç”¨ç¤ºä¾‹")
    curl_code = """
curl -X POST https://api.mochi-sentiment.com/v1/analyze \\
  -H "Authorization: Bearer YOUR_API_KEY" \\
  -H "Content-Type: application/json" \\
  -d '{
    "text": "è¿™å®¶åº—çš„æœåŠ¡çœŸæ˜¯å¤ªå¥½äº†å‘¢",
    "topic": "é¤å…è¯„ä»·"
  }'
"""
    st.code(curl_code, language="bash")

# ================= åŠŸèƒ½æ¨¡å— 3: ç³»ç»Ÿè®¾ç½® =================
def system_settings_module():
    st.markdown("### âš™ï¸ ç³»ç»Ÿè®¾ç½®")
    st.info("è°ƒæ•´ç³»ç»Ÿå‚æ•°ï¼Œè®¾ç½®å°†ä¿å­˜åœ¨å½“å‰ä¼šè¯ä¸­")
    
    st.markdown("#### ğŸšï¸ æ¨¡å‹å‚æ•°")
    
    # ç½®ä¿¡åº¦é˜ˆå€¼
    min_conf = st.slider(
        "æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.min_confidence,
        step=0.05,
        help="ä½äºæ­¤é˜ˆå€¼çš„é¢„æµ‹å°†è¢«æ ‡è®°ä¸ºä¸ç¡®å®š"
    )
    st.session_state.min_confidence = min_conf
    
    # æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
    show_debug = st.toggle(
        "æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—",
        value=st.session_state.show_debug,
        help="å¼€å¯åå°†æ˜¾ç¤ºæ¨¡å‹å†…éƒ¨å¤„ç†ç»†èŠ‚"
    )
    st.session_state.show_debug = show_debug
    
    st.markdown("#### ğŸ¨ ç•Œé¢è®¾ç½®")
    
    # ä¸»é¢˜é€‰æ‹©ï¼ˆæ¨¡æ‹Ÿï¼‰
    theme = st.selectbox(
        "ç•Œé¢ä¸»é¢˜",
        ["é»˜è®¤ä¸»é¢˜ (Mochi Pink)", "æ·±è‰²æ¨¡å¼ (æš‚æœªå®ç°)", "ç®€çº¦æ¨¡å¼ (æš‚æœªå®ç°)"],
        index=0
    )
    
    # è¯­è¨€é€‰æ‹©ï¼ˆæ¨¡æ‹Ÿï¼‰
    language = st.selectbox(
        "ç•Œé¢è¯­è¨€",
        ["ç®€ä½“ä¸­æ–‡", "English (æš‚æœªå®ç°)"],
        index=0
    )
    
    st.markdown("#### ğŸ“Š å½“å‰é…ç½®")
    config_data = {
        "å‚æ•°": ["ç½®ä¿¡åº¦é˜ˆå€¼", "è¯¦ç»†æ—¥å¿—", "ç•Œé¢ä¸»é¢˜", "è¯­è¨€"],
        "å€¼": [f"{min_conf:.2f}", "å¼€å¯" if show_debug else "å…³é—­", theme, language]
    }
    st.table(pd.DataFrame(config_data))
    
    if st.button("ğŸ’¾ ä¿å­˜è®¾ç½®"):
        st.success("âœ… è®¾ç½®å·²ä¿å­˜åˆ°å½“å‰ä¼šè¯")
        st.balloons()

# ================= åŠŸèƒ½æ¨¡å— 4: ç”¨æˆ·ä¸­å¿ƒ =================
def user_center_module():
    st.markdown("### ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ")
    
    if not st.session_state.logged_in:
        # ç™»å½•ç•Œé¢
        st.info("è¯·ç™»å½•ä»¥è®¿é—®ç”¨æˆ·ä¸­å¿ƒ")
        
        with st.form("login_form"):
            username = st.text_input("ç”¨æˆ·å", placeholder="admin")
            password = st.text_input("å¯†ç ", type="password", placeholder="123456")
            submit = st.form_submit_button("ğŸ” ç™»å½•")
            
            if submit:
                if username in USERS and USERS[username] == password:
                    st.session_state.logged_in = True
                    st.session_state.username = username
                    st.success(f"âœ… æ¬¢è¿å›æ¥ï¼Œ{username}ï¼")
                    st.rerun()
                else:
                    st.error("âŒ ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        
        st.caption("ğŸ’¡ æ¼”ç¤ºè´¦å·: admin / 123456 æˆ– demo / demo")
    
    else:
        # å·²ç™»å½•çŠ¶æ€
        st.success(f"âœ… å·²ç™»å½•: {st.session_state.username}")
        
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸšª é€€å‡ºç™»å½•"):
                st.session_state.logged_in = False
                st.session_state.username = ""
                st.rerun()
        
        st.markdown("#### ğŸ“Š ç”¨æˆ·ä¿¡æ¯")
        user_info = {
            "ç”¨æˆ·å": st.session_state.username,
            "è´¦æˆ·ç±»å‹": "ç®¡ç†å‘˜" if st.session_state.username == "admin" else "æ™®é€šç”¨æˆ·",
            "æ³¨å†Œæ—¶é—´": "2024-01-01",
            "ä¸Šæ¬¡ç™»å½•": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "ç´¯è®¡åˆ†æ": len(st.session_state.history)
        }
        st.table(pd.DataFrame([user_info]).T.rename(columns={0: "å€¼"}))
        
        st.markdown("#### ğŸ“œ å†å²åˆ†æè®°å½•")
        if st.session_state.history:
            history_df = pd.DataFrame(st.session_state.history)
            st.dataframe(history_df, use_container_width=True)
            
            # æä¾›ä¸‹è½½
            csv = history_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºå†å²è®°å½•",
                data=csv,
                file_name=f"history_{st.session_state.username}.csv",
                mime="text/csv"
            )
        else:
            st.info("æš‚æ— å†å²è®°å½•")

# ================= ä¸»ç¨‹åº =================
def main():
    st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON, layout="wide")
    set_style()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.image("https://api.dicebear.com/7.x/notionists/svg?seed=Mochi&backgroundColor=ffb7b2", width=100)
        st.title("Mochi æ§åˆ¶å°")
        st.caption("Ver 2.0.0 (Upgraded)")
        
        # æ˜¾ç¤ºç™»å½•çŠ¶æ€
        if st.session_state.logged_in:
            st.success(f"ğŸ‘¤ {st.session_state.username}")
        
        menu = st.radio(
            "åŠŸèƒ½å¯¼èˆª",
            ["ğŸš€ æƒ…æ„Ÿåˆ†æå®éªŒå®¤", "ğŸ“Š æ‰¹é‡æ•°æ®å¤„ç†", "ğŸ”Œ API æ¥å£æ–‡æ¡£", "âš™ï¸ ç³»ç»Ÿè®¾ç½®", "ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ"]
        )
        
        st.markdown("---")
        st.markdown("#### ğŸ› ï¸ å¿«é€Ÿè®¾ç½®")
        st.caption(f"ç½®ä¿¡åº¦é˜ˆå€¼: {st.session_state.min_confidence:.2f}")
        st.caption(f"è¯¦ç»†æ—¥å¿—: {'å¼€å¯' if st.session_state.show_debug else 'å…³é—­'}")
    
    # åŠ è½½æ¨¡å‹
    model, preprocessor = load_model()
    
    # æ ¹æ®èœå•é€‰æ‹©æ˜¾ç¤ºä¸åŒæ¨¡å—
    if menu == "ğŸš€ æƒ…æ„Ÿåˆ†æå®éªŒå®¤":
        sentiment_analysis_lab(model, preprocessor)
    elif menu == "ğŸ“Š æ‰¹é‡æ•°æ®å¤„ç†":
        if model and preprocessor:
            batch_processing_module(model, preprocessor)
        else:
            st.error("æ¨¡å‹æœªåŠ è½½")
    elif menu == "ğŸ”Œ API æ¥å£æ–‡æ¡£":
        api_documentation_module()
    elif menu == "âš™ï¸ ç³»ç»Ÿè®¾ç½®":
        system_settings_module()
    elif menu == "ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ":
        user_center_module()

# ================= æƒ…æ„Ÿåˆ†æå®éªŒå®¤ =================
def sentiment_analysis_lab(model, preprocessor):
    col_main, col_right = st.columns([2, 1])
    
    with col_main:
        st.title(f"{PAGE_ICON} Mochi")
        st.markdown("### ã€ä¸­æ–‡ã€‘çŸ­æ–‡æœ¬æƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
        st.caption("åŸºäº **è¶…å›¾ç¥ç»ç½‘ç»œ (HGNN) ä¸æ³¨æ„åŠ›æœºåˆ¶** çš„å¤šæ¨¡æ€æƒ…æ„Ÿè®¡ç®—å¼•æ“")
        
        with st.container():
            st.markdown("#### ğŸ“ æ–‡æœ¬è¾“å…¥")
            col_input1, col_input2 = st.columns([1, 2])
            with col_input1:
                input_topic = st.text_input("è¯­å¢ƒ/è¯é¢˜ (Topic)", placeholder="ä¾‹å¦‚ï¼šå¤–å–")
            with col_input2:
                input_text = st.text_input("è¯„è®ºå†…å®¹ (Text)", placeholder="è¯·è¾“å…¥éœ€è¦åˆ†æçš„ä¸­æ–‡çŸ­æ–‡æœ¬...")
                
            analyze_btn = st.button("å¼€å§‹åˆ†æ / Analyze âœ¨", use_container_width=True)
    
    # åˆ†æé€»è¾‘
    if analyze_btn and input_text and model and preprocessor:
        with col_main:
            with st.status("ğŸ§  Mochi æ­£åœ¨æ€è€ƒ...", expanded=True) as status:
                st.write("ğŸ” åˆ†è¯ä¸è¯æ€§æ ‡æ³¨ (HanLP)...")
                time.sleep(0.3)
                st.write("ğŸ•¸ï¸ æ„å»ºä¾å­˜å¥æ³•è¶…å›¾ (Dependency Hypergraph)...")
                time.sleep(0.3)
                st.write("ğŸ¯ æå–æ³¨æ„åŠ›æƒé‡ (Attention Weights)...")
                time.sleep(0.3)
                
                probs, hanlp_data, attention_weights, tokens_list = predict_with_attention(
                    model, preprocessor, input_text, input_topic
                )
                status.update(label="âœ… åˆ†æå®Œæˆ!", state="complete", expanded=False)
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            pred_label = probs.argmax()
            label_names = ['æ­£é¢', 'è´Ÿé¢', 'åè®½']
            st.session_state.history.append({
                'æ—¶é—´': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'æ–‡æœ¬': input_text[:30] + '...' if len(input_text) > 30 else input_text,
                'è¯é¢˜': input_topic,
                'æƒ…æ„Ÿ': label_names[pred_label],
                'ç½®ä¿¡åº¦': f"{probs[pred_label]:.2%}"
            })
            
            # ç»“æœå±•ç¤º
            if pred_label == 0:
                main_text, sub_text, emoji, color = "å¿ƒæƒ…ä¸é”™", "ã€æ­£å¸¸è¯­æ°”-æ­£é¢ã€‘", "ğŸ’–", "#ccffcc"
            elif pred_label == 1:
                main_text, sub_text, emoji, color = "ä½ å·²æ€¥å“­", "ã€æ­£å¸¸è¯­æ°”-è´Ÿé¢ã€‘", "ğŸ’”", "#f0f2f6"
            else:
                main_text, sub_text, emoji, color = "é˜´é˜³æ€ªæ°”", "ã€åè®½è­¦å‘Šï¼ã€‘", "ğŸ˜", "#FFB7B2"
            
            st.markdown(f"""
            <div class="result-card" style="background-color: {color};">
                <h1 style="color: #555; margin:0;">{emoji} {main_text}</h1>
                <h3 style="color: #333; margin:10px;">{sub_text}</h3>
                <p>ç½®ä¿¡åº¦: <strong>{probs[pred_label]:.2%}</strong></p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("#### ğŸ“Š æƒ…æ„Ÿå€¾å‘åˆ†å¸ƒ")
            col_p1, col_p2, col_p3 = st.columns(3)
            col_p1.metric("â¤ï¸ æ­£é¢", f"{probs[0]:.1%}")
            col_p1.progress(float(probs[0]))
            col_p2.metric("ğŸ’” è´Ÿé¢", f"{probs[1]:.1%}")
            col_p2.progress(float(probs[1]))
            col_p3.metric("ğŸ˜ åè®½", f"{probs[2]:.1%}")
            col_p3.progress(float(probs[2]))
        
        # Mochi è§†è§’ï¼ˆå³ä¾§ï¼‰
        with col_right:
            st.markdown("### ğŸ” Mochi çš„è§†è§’")
            
            # Tab 1: äº¤äº’å¼è¶…å›¾
            with st.expander("ğŸ•¸ï¸ è¶…å›¾ç»“æ„ï¼ˆå¯äº¤äº’ï¼‰", expanded=True):
                html = create_interactive_hypergraph(hanlp_data, attention_weights, tokens_list)
                if html:
                    components.html(html, height=500, scrolling=True)
                    st.caption("ğŸ’¡ èŠ‚ç‚¹å¤§å°å’Œé¢œè‰²è¡¨ç¤ºæ³¨æ„åŠ›æƒé‡ï¼Œå¯æ‹–æ‹½å’Œç¼©æ”¾")
                else:
                    st.warning("è¶…å›¾ç”Ÿæˆå¤±è´¥")
            
            # Tab 2: æ³¨æ„åŠ›çƒ­åŠ›å›¾
            with st.expander("ğŸ”¥ æ³¨æ„åŠ›çƒ­åŠ›å›¾", expanded=False):
                fig = create_attention_heatmap(attention_weights, tokens_list)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                    st.caption("ğŸ’¡ é¢œè‰²è¶Šæ·±è¡¨ç¤ºæ³¨æ„åŠ›æƒé‡è¶Šé«˜")
                else:
                    st.warning("çƒ­åŠ›å›¾ç”Ÿæˆå¤±è´¥")
            
            # è°ƒè¯•ä¿¡æ¯
            if st.session_state.show_debug:
                with st.expander("ğŸ› è°ƒè¯•ä¿¡æ¯", expanded=False):
                    st.json({
                        "tokens_count": len(tokens_list),
                        "attention_shape": attention_weights.shape,
                        "hanlp_keys": list(hanlp_data.keys()),
                        "device": str(DEVICE)
                    })
    
    elif not input_text:
        with col_main:
            st.info("ğŸ‘ˆ è¯·åœ¨ä¸Šæ–¹è¾“å…¥æ–‡æœ¬å¼€å§‹ä½“éªŒ")
            st.markdown("""
            > **Mochi** æ˜¯ä¸€ä¸ªèƒ½å¤Ÿå¬æ‡‚"è¨€å¤–ä¹‹æ„"çš„æ™ºèƒ½åŠ©æ‰‹ã€‚
            > * ğŸ˜„ **çœŸè¯šçš„èµç¾** (Positive)
            > * ğŸ˜¡ **ç›´ç™½çš„æ‰¹è¯„** (Negative)
            > * ğŸ˜ **é˜´é˜³æ€ªæ°”çš„è®½åˆº** (Sarcasm)
            """)

if __name__ == "__main__":
    main()
